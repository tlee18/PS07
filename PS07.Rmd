---
title: "STAT/MATH 495: Problem Set 07"
author: "Tim Lee"
date: "2017-10-24"
output:
  html_document:
    toc: true
    toc_float: true
    toc_depth: 2
    collapsed: false
    smooth_scroll: false
    df_print: kable
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE, fig.width=8, fig.height=4.5, message=FALSE, warning = FALSE
  )
set.seed(76)
options(digits = 4)

# Load packages
library(tidyverse)
library(broom)
library(knitr)

train <- read_csv("data/cs-training.csv") %>% 
  rename(Id = X1)
test <- read_csv("data/cs-test.csv") %>% 
  rename(Id = X1) 
submission <- read_csv("data/sampleEntry.csv")
```

Information on the competition can be found [here](https://www.kaggle.com/c/GiveMeSomeCredit/data).



# Collaboration

Please indicate who you collaborated with on this assignment: Pei Gong



# Build binary classifier

Build the binary classifier based on a single predictor variable: `DebtRatio`,
`age`, or `MonthlyIncome`. Justify this choice.

## Exploratory Analysis

* I initially tried doing exploratory analysis with faceting the plots into if there was a `Serious Delinquency in 2 Years`. However, given the size of the dataset, ggplot was sluggish. Thus, while I have the code included, I decided not to run it in order to focus on other parts of the analysis. 

* A more fruitful analysis on the best single predictor would be to see the Area Under the Curve (AUC) of a Receiver Operating Characteristic (ROC) Curve. 

```{r, echo = TRUE, eval=FALSE}
# Debt Ratio
ggplot(data = train, aes(x = DebtRatio)) +
  geom_histogram(binwidth = 2) +
  facet_grid(SeriousDlqin2yrs ~ .) +
  coord_cartesian(xlim = c(0, 50)) +
  labs(x = "Debt Ratio", y = "Count", title = "Serious Delinquency in 2 Years")

# Age
ggplot(data = train, aes(x = age)) +
  geom_histogram(binwidth = 2) +
  facet_grid(SeriousDlqin2yrs ~ .) +
  coord_cartesian(xlim = c(0, 50)) +
  labs(x = "Debt Ratio", y = "Count", title = "Serious Delinquency in 2 Years")

# Monthly Income
ggplot(data = train, aes(x = MonthlyIncome)) +
  geom_histogram(binwidth = 2) +
  facet_grid(SeriousDlqin2yrs ~ .) +
  coord_cartesian(xlim = c(0, 50)) +
  labs(x = "Debt Ratio", y = "Count", title = "Serious Delinquency in 2 Years")
```


## Creating the Logistic Regressions

* I identified a logistic regression model (categorical outcome, quantitative predictors) for each of the three potential variables. This would allow me to see which option was the best with the AUC. Note that the p-values sometimes show as 0 in the table. This is due to rounding to 4 digits, and the actual p-value is simply very, very small (but not exactly at 0).

### Logistic Regression: Debt Ratio
```{r, echo=FALSE}
modelDebtRatio <- glm(SeriousDlqin2yrs~DebtRatio, data=train, family="binomial")
modelDebtRatio %>% 
  broom::tidy(conf.int=TRUE, title = "Logistic Regression: Debt Ratio")
```


### Logistic Regression: Age
```{r, echo=FALSE}
modelAge <- glm(SeriousDlqin2yrs~age, data=train, family="binomial")
modelAge %>% 
  broom::tidy(conf.int=TRUE)
```

### Logistic Regression: Monthly Income
```{r, echo = FALSE}
modelMonthlyIncome <- glm(SeriousDlqin2yrs ~ MonthlyIncome, data=train, family="binomial")
modelMonthlyIncome %>% 
  broom::tidy(conf.int=TRUE)
```


## Making Predictions with AUC
```{r, include= FALSE}
getAUC <- function(trainModel){
  ROC_data <- trainModel %>% 
    group_by(p_hat) %>%
    summarise(
      Positive = sum(SeriousDlqin2yrs),
      Negative = n() - sum(SeriousDlqin2yrs)
    ) %>%
    arrange(-p_hat) %>%
    mutate(
      TPR = cumsum(Positive) / sum(Positive),
      FPR = cumsum(Negative) / sum(Negative)
    )
  
  AUC <- ROC_data %>% 
    summarise(AUC = sum(diff(FPR) * na.omit(lead(TPR) + TPR)) / 2)

  return(AUC)
}

```


* The Age variable has the highest AUC at around 0.64. This was better than the other options which did not reach about 0.6. `Monthly Income` was around 0.58, and `Debt Ratio` was around 0.48 (or 0.52 if reversed).

```{r, echo = FALSE}
trainModel1 <- modelMonthlyIncome %>% 
  broom::augment() %>% 
  as_tibble() %>% 
  mutate(p_hat = 1/(1+exp(-.fitted))) 
monthlyIncomeAUC <- as.numeric(getAUC(trainModel1))

trainModel2 <- modelAge %>% 
  broom::augment() %>% 
  as_tibble() %>% 
  mutate(p_hat = 1/(1+exp(-.fitted))) 
ageAUC <- as.numeric(getAUC(trainModel2))

trainModel3 <- modelDebtRatio %>% 
  broom::augment() %>% 
  as_tibble() %>% 
  mutate(p_hat = 1/(1+exp(-.fitted))) 
debtRatioAUC <- as.numeric(getAUC(trainModel3))




variables <- c("Monthly Income", "Age", "Debt Ratio")
values <- c(monthlyIncomeAUC, ageAUC, debtRatioAUC)

AUCtable <- as.data.frame(setNames(values, variables))
names(AUCtable) <- "AUC"
AUCtable %>% knitr::kable(digits=4)

```



# ROC curve
Based on the ultimate classifier you choose, plot a corresponding ROC curve.

* I chose `age` as the ultimate classifer, since it had the highest AUC.

```{r, echo = FALSE}
ROC_data <- trainModel2 %>% 
    group_by(p_hat) %>%
    summarise(
      Positive = sum(SeriousDlqin2yrs),
      Negative = n() - sum(SeriousDlqin2yrs)
    ) %>%
    arrange(-p_hat) %>%
    mutate(
      TPR = cumsum(Positive) / sum(Positive),
      FPR = cumsum(Negative) / sum(Negative)
    )
  
AUC <- ROC_data %>% 
  summarise(AUC = sum(diff(FPR) * na.omit(lead(TPR) + TPR)) / 2)
  
ggplot(ROC_data, aes(FPR, TPR)) +
    geom_line() +
    geom_abline(lty = 2) +
    labs(
      x = expression(paste("False Positive Rate(", p, "*)")),
      y = expression(paste("True Positive Rate(", p, "*)")), 
      title = paste("ROC Curve as a Parametric Function of p*. Area Under Curve = ", round(AUC,3), sep=""))
```


# ROC curve for random guessing

* Instead of using any predictor information as you did above, switch your
predictions to random guesses and plot the resulting ROC curve.

* I shuffled with replacement the `SeriousDlqin2yrs` variable in order to break any relationship. As a result, it simulates random guessing and generates an AUC of around 0.501. This is generally consistent with the theoretical AUC value of 0.5 that represents random guessing. 
 
```{r}
shuffled_SeriousDlq <- train["SeriousDlqin2yrs"] %>% 
  sample_frac(size = 1, replace = TRUE)

train_random <- train %>% 
  select(-SeriousDlqin2yrs) %>%
  bind_cols(., shuffled_SeriousDlq)

modelRandom <- glm(SeriousDlqin2yrs ~ age, data=train_random, family="binomial")
```
 
 
```{r, echo = FALSE}
trainModel4 <- modelRandom %>% 
  broom::augment() %>% 
  as_tibble() %>% 
  mutate(p_hat = 1/(1+exp(-.fitted))) 

ROC_data <- trainModel4 %>% 
    group_by(p_hat) %>%
    summarise(
      Positive = sum(SeriousDlqin2yrs),
      Negative = n() - sum(SeriousDlqin2yrs)
    ) %>%
    arrange(-p_hat) %>%
    mutate(
      TPR = cumsum(Positive) / sum(Positive),
      FPR = cumsum(Negative) / sum(Negative)
    )
  
AUC <- ROC_data %>% 
  summarise(AUC = sum(diff(FPR) * na.omit(lead(TPR) + TPR)) / 2)
  
ggplot(ROC_data, aes(FPR, TPR)) +
    geom_line() +
    geom_abline(lty = 2) +
    labs(
      x = expression(paste("False Positive Rate(", p, "*)")),
      y = expression(paste("True Positive Rate(", p, "*)")), 
      title = paste("ROC Curve as a Parametric Function of p*. Area Under Curve = ", round(AUC,3), sep=""))

```


# Kaggle Prediction

```{r}
predictions <- modelAge %>% 
  broom::augment(newdata=test) %>% 
  mutate(p_hat = 1/(1 + exp(-.fitted))) %>%
  select(Probability = p_hat)

submission$Probability <- predictions$Probability
write.csv(submission, "submission.csv", row.names=FALSE)

```

* My Kaggle score is shown in the screenshot. The score is about 0.64 using just the one predictor of `age`.